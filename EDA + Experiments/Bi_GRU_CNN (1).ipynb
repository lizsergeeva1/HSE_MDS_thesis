{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7456fb81b270471592447edfb216f38c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fed4375b123480d8f28f652f3b24ee0",
              "IPY_MODEL_dff242b8c0454c2a9c5222d34b45a9c1",
              "IPY_MODEL_cb03812b6aa54153976493f639887e5d"
            ],
            "layout": "IPY_MODEL_164db336d05d4e78b189c6df49434635"
          }
        },
        "8fed4375b123480d8f28f652f3b24ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_684a38625e3e46c380eb9db2372199b4",
            "placeholder": "​",
            "style": "IPY_MODEL_7034799aadbd414a83acaaa4870a9c73",
            "value": "100%"
          }
        },
        "dff242b8c0454c2a9c5222d34b45a9c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eef5b5df8d6a4fb28beab6040f96ed88",
            "max": 14335,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3900a4b4801048d2be04e416dd3346d9",
            "value": 14335
          }
        },
        "cb03812b6aa54153976493f639887e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d01e1a10bb524ed3a306f00375c186b5",
            "placeholder": "​",
            "style": "IPY_MODEL_757b5ca93a3044878ef08c72ce54dd80",
            "value": " 14335/14335 [03:25&lt;00:00, 55.77it/s]"
          }
        },
        "164db336d05d4e78b189c6df49434635": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "684a38625e3e46c380eb9db2372199b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7034799aadbd414a83acaaa4870a9c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eef5b5df8d6a4fb28beab6040f96ed88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3900a4b4801048d2be04e416dd3346d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d01e1a10bb524ed3a306f00375c186b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "757b5ca93a3044878ef08c72ce54dd80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ME00AfjSNswo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from sklearn.metrics import make_scorer\n",
        "import spacy\n",
        "import re\n",
        "import string\n",
        "from gensim.models import KeyedVectors\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "from nltk.corpus import stopwords\n",
        "from pymystem3 import Mystem\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from bs4 import BeautifulSoup\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import GRU,Conv1D,MaxPooling1D,GlobalMaxPooling1D, Flatten,Embedding,BatchNormalization\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "UhIwkfopOUTr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "ecc6LidRQShV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m nltk.downloader all"
      ],
      "metadata": {
        "id": "CSQtAXUwNvqS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e162cb-07d7-4ec2-f80c-5d8c3932e134"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()"
      ],
      "metadata": {
        "id": "ZOMFLTqPRHQ1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXloLvjUN4vb",
        "outputId": "26611b1c-3393-4be9-8124-79efa0dc8f04"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('drive/MyDrive/cleaned_data_final3.csv')\n",
        "df_new2 = df[['area_id', 'prof_name', 'name',\n",
        "            'mean_salary', 'description','schedule', 'experience_rus','employment','quick_responses_allowed','premium',\n",
        "            'allow_messages','accept_temporary', 'first_language', 'key_skills', 'mean_salary_all', 'city']]"
      ],
      "metadata": {
        "id": "E_mCOCTbN5IY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new2 = df_new2.drop_duplicates(subset=['description'])"
      ],
      "metadata": {
        "id": "wD4VzqR1OL2B"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names_to_remove = ['Технический писатель', 'Продуктовый аналитик' , 'Директор по информационным технологиям (CIO)','Дата-сайентист',\n",
        "                   'Руководитель отдела аналитики', 'Методолог', 'Гейм-дизайнер', 'Арт-директор, креативный директор']\n",
        "df_new2 = df_new2[~df_new2['prof_name'].isin(names_to_remove)]"
      ],
      "metadata": {
        "id": "dYHHXwJhOMPK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PreprocessData:\n",
        "    def __init__ (self, data, y, stem_method=Mystem()):\n",
        "        \"\"\"Clean data and preprocess text\"\"\"\n",
        "        self.data = data\n",
        "        self.y = y\n",
        "        self.mystem = stem_method\n",
        "        # self.show_stats = show_stats\n",
        "\n",
        "    def fill_nans(self):\n",
        "        self.data[y] = self.data[y].fillna(0)\n",
        "        for col in self.data.select_dtypes(['object']).columns:\n",
        "            self.data[col] = self.data[col].fillna('')\n",
        "\n",
        "    def drop_duplicates(self):\n",
        "        self.data = self.data.drop_duplicates(subset=['description'])\n",
        "\n",
        "    def clean_and_lemmatize(self, text):\n",
        "        # clean punctuation and stop words\n",
        "        text = text.lower()\n",
        "        words = re.findall(r'\\b\\w+\\b', text)\n",
        "        stop_words = set(stopwords.words('russian'))\n",
        "        words = [w for w in words if w not in stop_words]\n",
        "        # clean_text = ' '.join(words)\n",
        "\n",
        "        # lemmatize\n",
        "        # words = text.split()\n",
        "        lemmas = [self.mystem.lemmatize(word)[0] for word in words]\n",
        "        lemmatized_text = ' '.join(lemmas)\n",
        "        return lemmatized_text\n",
        "\n",
        "    def get_cleaned_data(self):\n",
        "        self.drop_duplicates()\n",
        "        self.fill_nans()\n",
        "        self.data['descr_clean'] = self.data['description'].progress_apply(self.clean_and_lemmatize)\n",
        "        return self.data.reset_index(drop=True)\n",
        "\n",
        "    def get_stats(self, cat_features):\n",
        "        print(self.data.info(), '\\n')\n",
        "        print(\"Numerical features' analysis\")\n",
        "        plt.figure()\n",
        "        self.data[self.y].hist(bins=30)\n",
        "        plt.title(f'{self.y} distribution')\n",
        "        plt.show;\n",
        "        display(self.data.describe().T)\n",
        "\n",
        "        print('\\n', \"Categorical features' analysis\")\n",
        "        display(self.data.describe(include=object).T)\n",
        "        for col in cat_features:\n",
        "            plt.figure()\n",
        "            self.data[col].value_counts().head(10).plot(kind='barh', color='pink')\n",
        "            plt.title(f'{col} frequency')\n",
        "            plt.show();"
      ],
      "metadata": {
        "id": "BjQEGWrHQ-JG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d38c694-6d24-41d5-ccd2-7a67cad17db1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = 'mean_salary_all'\n",
        "cat_features = ['prof_name', 'city', 'schedule', 'employment', 'experience_rus']\n",
        "text_features = ['key_skills', 'descr_clean', 'name']"
      ],
      "metadata": {
        "id": "I9P1r6QwREmG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_processed = PreprocessData(df_new2, y)\n",
        "df_new2 = data_processed.get_cleaned_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7456fb81b270471592447edfb216f38c",
            "8fed4375b123480d8f28f652f3b24ee0",
            "dff242b8c0454c2a9c5222d34b45a9c1",
            "cb03812b6aa54153976493f639887e5d",
            "164db336d05d4e78b189c6df49434635",
            "684a38625e3e46c380eb9db2372199b4",
            "7034799aadbd414a83acaaa4870a9c73",
            "eef5b5df8d6a4fb28beab6040f96ed88",
            "3900a4b4801048d2be04e416dd3346d9",
            "d01e1a10bb524ed3a306f00375c186b5",
            "757b5ca93a3044878ef08c72ce54dd80"
          ]
        },
        "id": "qm4_d2QhRBF-",
        "outputId": "ef09e7ce-b9d6-4b01-8b62-662159066c08"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/14335 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7456fb81b270471592447edfb216f38c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have several text columns: vacancy name, key skills and description. Let's try to use Bi-GRU-CNN on this data."
      ],
      "metadata": {
        "id": "u8aA5oIFOhs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_new2['all_text'] = df_new2['name'].str.lower()  + '. '+ df_new2['key_skills'].fillna('').str.lower() +  '. ' + df_new2['description'].str.lower()"
      ],
      "metadata": {
        "id": "fHh__576Od64"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_new2['all_text'].values, df_new2.mean_salary_all.values.astype(int), test_size=0.2, random_state=10)"
      ],
      "metadata": {
        "id": "yrpZEbTUPrNv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "num_rows = df_new2['all_text'].shape[0]\n",
        "tokenizer.fit_on_texts(df_new2['all_text'].values)\n",
        "row_max_length = max([len(x.split()) for x in df_new2['all_text'].values])\n",
        "vocabulary_size = len(tokenizer.word_index) + 1\n",
        "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_tokens = tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "_5dpbzDePXLT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pad = pad_sequences(X_train_tokens, maxlen=row_max_length, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_tokens, maxlen=row_max_length, padding='post')"
      ],
      "metadata": {
        "id": "nnd2ocw-P02W"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 256\n",
        "\n",
        "learning_rate = 0.01\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, EMBEDDING_DIM, input_length=row_max_length))\n",
        "model.add(Bidirectional(GRU(units=128, return_sequences=True)))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='linear'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 1, activation='linear'))\n",
        "model.compile(optimizer=optimizer, loss='mean_absolute_error', metrics=['mae'])\n",
        "\n",
        "\n",
        "epochs=15\n",
        "batch_size=128"
      ],
      "metadata": {
        "id": "WmM_LMeOP9Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLgP-bq8Efho",
        "outputId": "1e3137dd-3ce6-4b22-f282-2dbef5c3d8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1145, 256)         21398272  \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 1145, 256)         296448    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 1145, 64)          49216     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 572, 64)           0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 36608)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 36608)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 36609     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21780545 (83.09 MB)\n",
            "Trainable params: 21780545 (83.09 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/gpu:0'):\n",
        "  model.fit(X_train_pad,y_train,epochs=epochs,batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oud1M3O7QWPR",
        "outputId": "a6ae3006-dcba-43c4-fed3-0ecf68cb5e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "90/90 [==============================] - 30s 293ms/step - loss: 51826.5234 - mae: 51826.5234\n",
            "Epoch 2/15\n",
            "90/90 [==============================] - 26s 285ms/step - loss: 42157.7109 - mae: 42157.7109\n",
            "Epoch 3/15\n",
            "90/90 [==============================] - 27s 298ms/step - loss: 36578.8867 - mae: 36578.8867\n",
            "Epoch 4/15\n",
            "90/90 [==============================] - 25s 267ms/step - loss: 30351.8320 - mae: 30351.8320\n",
            "Epoch 5/15\n",
            "90/90 [==============================] - 27s 298ms/step - loss: 26208.0332 - mae: 26208.0332\n",
            "Epoch 6/15\n",
            "90/90 [==============================] - 22s 243ms/step - loss: 23401.3789 - mae: 23401.3789\n",
            "Epoch 7/15\n",
            "90/90 [==============================] - 22s 247ms/step - loss: 20832.3613 - mae: 20832.3613\n",
            "Epoch 8/15\n",
            "90/90 [==============================] - 21s 231ms/step - loss: 18751.4414 - mae: 18751.4414\n",
            "Epoch 9/15\n",
            "90/90 [==============================] - 21s 236ms/step - loss: 17945.3496 - mae: 17945.3496\n",
            "Epoch 10/15\n",
            "90/90 [==============================] - 21s 236ms/step - loss: 17113.9141 - mae: 17113.9141\n",
            "Epoch 11/15\n",
            "90/90 [==============================] - 20s 227ms/step - loss: 15176.6895 - mae: 15176.6895\n",
            "Epoch 12/15\n",
            "90/90 [==============================] - 20s 224ms/step - loss: 14644.1572 - mae: 14644.1572\n",
            "Epoch 13/15\n",
            "90/90 [==============================] - 20s 221ms/step - loss: 13450.3721 - mae: 13450.3721\n",
            "Epoch 14/15\n",
            "90/90 [==============================] - 19s 212ms/step - loss: 12504.4131 - mae: 12504.4131\n",
            "Epoch 15/15\n",
            "90/90 [==============================] - 19s 214ms/step - loss: 12199.5176 - mae: 12199.5176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test_pad, y_test)\n",
        "print('Test MAE:', scores[0])\n",
        "y_pred = model.predict(X_test_pad).astype(int)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('R2 score:', round(r2 * 100, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28Qa4zPJQYw6",
        "outputId": "e0dc3fda-daec-4fcb-abc1-ac209c636b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 4s 35ms/step - loss: 30529.5254 - mae: 30529.5254\n",
            "Test MAE: 30529.525390625\n",
            "90/90 [==============================] - 4s 32ms/step\n",
            "R2 score: 52.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see model results without description. Only with name, key skills."
      ],
      "metadata": {
        "id": "5e4RWuQsTWnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_new2['all_text_wo_descr'] = df_new2['name'].str.lower()  + '. '+ df_new2['key_skills'].fillna('').str.lower()"
      ],
      "metadata": {
        "id": "rk3lc1ybTgxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_new2['all_text_wo_descr'].values, df_new2.mean_salary_all.values.astype(int), test_size=0.2, random_state=10)"
      ],
      "metadata": {
        "id": "Zqj5A8asTlXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "num_rows = df_new2['all_text_wo_descr'].shape[0]\n",
        "tokenizer.fit_on_texts(df_new2['all_text_wo_descr'].values)\n",
        "row_max_length = max([len(x.split()) for x in df_new2['all_text_wo_descr'].values])\n",
        "vocabulary_size = len(tokenizer.word_index) + 1\n",
        "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_tokens = tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "kQ8KPPJpTnmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pad1 = pad_sequences(X_train_tokens, maxlen=row_max_length, padding='post')\n",
        "X_test_pad1 = pad_sequences(X_test_tokens, maxlen=row_max_length, padding='post')"
      ],
      "metadata": {
        "id": "7qyl-wZqTrz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 256\n",
        "\n",
        "learning_rate = 0.01\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, EMBEDDING_DIM, input_length=row_max_length))\n",
        "model.add(Bidirectional(GRU(units=128, return_sequences=True)))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='linear'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 1, activation='linear'))\n",
        "model.compile(optimizer=optimizer, loss='mean_absolute_error', metrics=['mae'])\n",
        "\n",
        "\n",
        "epochs=15\n",
        "batch_size=128"
      ],
      "metadata": {
        "id": "vA9LUH4OTtVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/gpu:0'):\n",
        "  model.fit(X_train_pad1, y_train, epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t08PenvPTvFA",
        "outputId": "2daa7c2c-81fe-42d8-a327-3d244c9b68c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "90/90 [==============================] - 18s 125ms/step - loss: 56542.5430 - mae: 56542.5430\n",
            "Epoch 2/15\n",
            "90/90 [==============================] - 6s 64ms/step - loss: 44646.9922 - mae: 44646.9922\n",
            "Epoch 3/15\n",
            "90/90 [==============================] - 5s 56ms/step - loss: 38527.9375 - mae: 38527.9375\n",
            "Epoch 4/15\n",
            "90/90 [==============================] - 4s 39ms/step - loss: 34515.0312 - mae: 34515.0312\n",
            "Epoch 5/15\n",
            "90/90 [==============================] - 8s 92ms/step - loss: 32175.8516 - mae: 32175.8516\n",
            "Epoch 6/15\n",
            "90/90 [==============================] - 2s 27ms/step - loss: 30379.9844 - mae: 30379.9844\n",
            "Epoch 7/15\n",
            "90/90 [==============================] - 3s 29ms/step - loss: 29340.4707 - mae: 29340.4707\n",
            "Epoch 8/15\n",
            "90/90 [==============================] - 2s 24ms/step - loss: 28325.7949 - mae: 28325.7949\n",
            "Epoch 9/15\n",
            "90/90 [==============================] - 2s 22ms/step - loss: 27824.6426 - mae: 27824.6426\n",
            "Epoch 10/15\n",
            "90/90 [==============================] - 2s 25ms/step - loss: 27179.0723 - mae: 27179.0723\n",
            "Epoch 11/15\n",
            "90/90 [==============================] - 2s 28ms/step - loss: 26703.0020 - mae: 26703.0020\n",
            "Epoch 12/15\n",
            "90/90 [==============================] - 2s 22ms/step - loss: 26533.9512 - mae: 26533.9512\n",
            "Epoch 13/15\n",
            "90/90 [==============================] - 3s 28ms/step - loss: 25820.2969 - mae: 25820.2969\n",
            "Epoch 14/15\n",
            "90/90 [==============================] - 2s 24ms/step - loss: 25391.3184 - mae: 25391.3184\n",
            "Epoch 15/15\n",
            "90/90 [==============================] - 2s 27ms/step - loss: 25365.0527 - mae: 25365.0527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test_pad1, y_test)\n",
        "print('Test MAE:', scores[0])\n",
        "y_pred = model.predict(X_test_pad1).astype(int)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('R2 score:', round(r2 * 100, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4_OAfzpUv1x",
        "outputId": "612676be-b3c5-42d0-cddf-9c0999fa408e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 2s 7ms/step - loss: 34189.5742 - mae: 34189.5742\n",
            "Test MAE: 34189.57421875\n",
            "90/90 [==============================] - 1s 4ms/step\n",
            "R2 score: 41.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see other variables like text except the description"
      ],
      "metadata": {
        "id": "LbH72YtqVWrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_new2['total'] = df_new2['city'] + '. ' + df_new2['schedule'].str.lower() +'. '+ df_new2['name'] + '. ' + df_new2['employment'].str.lower() +'. ' +  df_new2['prof_name'].str.lower()  + '. ' + df_new2['experience_rus'].str.lower() +'. '+ df_new2['key_skills'].fillna('')"
      ],
      "metadata": {
        "id": "KJ8ieKofVWXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_new2['total'].values, df_new2.mean_salary_all.values.astype(int), test_size=0.2, random_state=10)"
      ],
      "metadata": {
        "id": "LGpdqDWZVBeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "num_rows = df_new2['total'].shape[0]\n",
        "tokenizer.fit_on_texts(df_new2['total'].values)\n",
        "row_max_length = max([len(x.split()) for x in df_new2['total'].values])\n",
        "vocabulary_size = len(tokenizer.word_index) + 1\n",
        "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_tokens = tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "qkSfCDlAVdjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pad2 = pad_sequences(X_train_tokens, maxlen=row_max_length, padding='post')\n",
        "X_test_pad2 = pad_sequences(X_test_tokens, maxlen=row_max_length, padding='post')"
      ],
      "metadata": {
        "id": "rVbzKSNDVihU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 256\n",
        "\n",
        "learning_rate = 0.01\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, EMBEDDING_DIM, input_length=row_max_length))\n",
        "model.add(Bidirectional(GRU(units=128, return_sequences=True)))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='linear'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 1, activation='linear'))\n",
        "model.compile(optimizer=optimizer, loss='mean_absolute_error', metrics=['mae'])\n",
        "\n",
        "\n",
        "epochs=15\n",
        "batch_size=128"
      ],
      "metadata": {
        "id": "5kwT3o1FV0zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 256\n",
        "\n",
        "learning_rate = 0.01\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, EMBEDDING_DIM, input_length=row_max_length))\n",
        "model.add(Bidirectional(GRU(units=128, return_sequences=True)))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='linear'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 1, activation='linear'))\n",
        "model.compile(optimizer=optimizer, loss='mean_absolute_error', metrics=['mae'])\n",
        "\n",
        "\n",
        "epochs=15\n",
        "batch_size=128"
      ],
      "metadata": {
        "id": "YXEa9MhQQnjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/gpu:0'):\n",
        "  model.fit(X_train_pad2, y_train, epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p153B3C4V3v3",
        "outputId": "9fa27340-a230-4c98-f96e-290adfff73a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "90/90 [==============================] - 22s 167ms/step - loss: 56213.3086 - mae: 56213.3086\n",
            "Epoch 2/15\n",
            "90/90 [==============================] - 5s 58ms/step - loss: 38500.2188 - mae: 38500.2188\n",
            "Epoch 3/15\n",
            "90/90 [==============================] - 4s 41ms/step - loss: 30107.4062 - mae: 30107.4062\n",
            "Epoch 4/15\n",
            "90/90 [==============================] - 4s 47ms/step - loss: 26740.2070 - mae: 26740.2070\n",
            "Epoch 5/15\n",
            "90/90 [==============================] - 4s 44ms/step - loss: 24624.1699 - mae: 24624.1699\n",
            "Epoch 6/15\n",
            "90/90 [==============================] - 3s 33ms/step - loss: 23805.9883 - mae: 23805.9883\n",
            "Epoch 7/15\n",
            "90/90 [==============================] - 3s 30ms/step - loss: 22898.1426 - mae: 22898.1426\n",
            "Epoch 8/15\n",
            "90/90 [==============================] - 3s 28ms/step - loss: 22107.0078 - mae: 22107.0078\n",
            "Epoch 9/15\n",
            "90/90 [==============================] - 2s 28ms/step - loss: 21499.4824 - mae: 21499.4824\n",
            "Epoch 10/15\n",
            "90/90 [==============================] - 2s 26ms/step - loss: 20915.9336 - mae: 20915.9336\n",
            "Epoch 11/15\n",
            "90/90 [==============================] - 2s 26ms/step - loss: 20334.3887 - mae: 20334.3887\n",
            "Epoch 12/15\n",
            "90/90 [==============================] - 2s 27ms/step - loss: 19908.5039 - mae: 19908.5039\n",
            "Epoch 13/15\n",
            "90/90 [==============================] - 2s 23ms/step - loss: 19480.4414 - mae: 19480.4414\n",
            "Epoch 14/15\n",
            "90/90 [==============================] - 3s 32ms/step - loss: 19291.8770 - mae: 19291.8770\n",
            "Epoch 15/15\n",
            "90/90 [==============================] - 3s 34ms/step - loss: 19080.7402 - mae: 19080.7402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test_pad2, y_test)\n",
        "print('Test MAE:', scores[0])\n",
        "y_pred = model.predict(X_test_pad2).astype(int)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('R2 score:', round(r2 * 100, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFR2SuorV6EZ",
        "outputId": "b66a1413-be3b-48de-e55f-76a78fd5bc8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 2s 7ms/step - loss: 26546.1992 - mae: 26546.1992\n",
            "Test MAE: 26546.19921875\n",
            "90/90 [==============================] - 1s 5ms/step\n",
            "R2 score: 63.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see add description"
      ],
      "metadata": {
        "id": "n9N6IkuyWWIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_new2['total'] = df_new2['city'] + '. ' + df_new2['schedule'].str.lower() +'. '+ df_new2['name'] + '. ' + df_new2['employment'].str.lower() +'. ' +  df_new2['prof_name'].str.lower()  + '. ' + df_new2['experience_rus'].str.lower() +'. '+ df_new2['key_skills'].fillna('') + '. '+ df_new2['descr_clean'].str.lower()"
      ],
      "metadata": {
        "id": "p3lvvqRcWLIw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "num_rows = df_new2['total'].shape[0]\n",
        "tokenizer.fit_on_texts(df_new2['total'].values)\n",
        "row_max_length = max([len(x.split()) for x in df_new2['total'].values])\n",
        "vocabulary_size = len(tokenizer.word_index) + 1\n",
        "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_tokens = tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "A2Xxpde8Whs2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pad3 = pad_sequences(X_train_tokens, maxlen=row_max_length, padding='post')\n",
        "X_test_pad3 = pad_sequences(X_test_tokens, maxlen=row_max_length, padding='post')"
      ],
      "metadata": {
        "id": "pUKePyqEWkr5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 256\n",
        "\n",
        "learning_rate = 0.01\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, EMBEDDING_DIM, input_length=row_max_length))\n",
        "model.add(Bidirectional(GRU(units=128, return_sequences=True)))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 1, activation='linear'))\n",
        "model.compile(optimizer=optimizer, loss='mean_absolute_error', metrics=['mae'])\n",
        "\n",
        "\n",
        "epochs=15\n",
        "batch_size=128"
      ],
      "metadata": {
        "id": "hHgAn8CnWm6l"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/gpu:0'):\n",
        "  model.fit(X_train_pad3, y_train, epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpJ2PK4DWrXm",
        "outputId": "0eaaa7d5-c2a8-42bb-d142-f522428a0c33"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "90/90 [==============================] - 28s 215ms/step - loss: 51476.5000 - mae: 51476.5000\n",
            "Epoch 2/15\n",
            "90/90 [==============================] - 18s 198ms/step - loss: 37311.6602 - mae: 37311.6602\n",
            "Epoch 3/15\n",
            "90/90 [==============================] - 18s 199ms/step - loss: 30579.0586 - mae: 30579.0586\n",
            "Epoch 4/15\n",
            "90/90 [==============================] - 17s 186ms/step - loss: 27110.4648 - mae: 27110.4648\n",
            "Epoch 5/15\n",
            "90/90 [==============================] - 16s 174ms/step - loss: 23790.3711 - mae: 23790.3711\n",
            "Epoch 6/15\n",
            "90/90 [==============================] - 16s 172ms/step - loss: 21446.5000 - mae: 21446.5000\n",
            "Epoch 7/15\n",
            "90/90 [==============================] - 16s 179ms/step - loss: 19769.2148 - mae: 19769.2148\n",
            "Epoch 8/15\n",
            "90/90 [==============================] - 16s 181ms/step - loss: 18372.6387 - mae: 18372.6387\n",
            "Epoch 9/15\n",
            "90/90 [==============================] - 15s 165ms/step - loss: 17119.9883 - mae: 17119.9883\n",
            "Epoch 10/15\n",
            "90/90 [==============================] - 14s 160ms/step - loss: 16512.9551 - mae: 16512.9551\n",
            "Epoch 11/15\n",
            "90/90 [==============================] - 15s 163ms/step - loss: 15509.3701 - mae: 15509.3701\n",
            "Epoch 12/15\n",
            "90/90 [==============================] - 15s 170ms/step - loss: 15099.0859 - mae: 15099.0859\n",
            "Epoch 13/15\n",
            "90/90 [==============================] - 15s 162ms/step - loss: 14326.8945 - mae: 14326.8945\n",
            "Epoch 14/15\n",
            "90/90 [==============================] - 14s 159ms/step - loss: 13755.7256 - mae: 13755.7256\n",
            "Epoch 15/15\n",
            "90/90 [==============================] - 15s 163ms/step - loss: 13566.2061 - mae: 13566.2061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test_pad3, y_test)\n",
        "print('Test MAE:', scores[0])\n",
        "y_pred = model.predict(X_test_pad3).astype(int)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('R2 score:', round(r2, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9PaYNcVWsbT",
        "outputId": "be7c8d29-2e44-4e47-8a9f-9a6a51ab214c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 3s 33ms/step - loss: 28740.3828 - mae: 28740.3828\n",
            "Test MAE: 28740.3828125\n",
            "90/90 [==============================] - 2s 26ms/step\n",
            "R2 score: 0.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_review_text(text):\n",
        "\n",
        "    text = text.lower()\n",
        "    words = re.findall(r'\\b\\w+\\b', text)\n",
        "    stop_words = set(stopwords.words('russian'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    clean_text = ' '.join(words)\n",
        "\n",
        "    return clean_text\n",
        "\n",
        "\n",
        "mystem = Mystem()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    words = text.split()\n",
        "    lemmas = [mystem.lemmatize(word)[0] for word in words]\n",
        "    lemmatized_text = ' '.join(lemmas)\n",
        "\n",
        "    return lemmatized_text\n",
        "df_new2['text_clean'] = df_new2['description'].apply(clean_review_text)\n",
        "\n",
        "df_new2['lemmatized_text'] = df_new2['text_clean'].apply(lemmatize_text)"
      ],
      "metadata": {
        "id": "mpMgW4jTteRM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new2['total'] = df_new2['city'] + '. ' + df_new2['schedule'].str.lower() +'. '+ df_new2['name'] + '. ' + df_new2['employment'].str.lower() +'. ' +  df_new2['prof_name'].str.lower()  + '. ' + df_new2['experience_rus'].str.lower() +'. '+ df_new2['key_skills'].fillna('') + '. '+ df_new2['lemmatized_text'].str.lower()"
      ],
      "metadata": {
        "id": "ap8XtqjnthZ4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_new2['total'].values, df_new2.mean_salary_all.values.astype(int), test_size=0.2, random_state=10)"
      ],
      "metadata": {
        "id": "WoV7ptqbtozj"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "num_rows = df_new2['total'].shape[0]\n",
        "tokenizer.fit_on_texts(df_new2['total'].values)\n",
        "row_max_length = max([len(x.split()) for x in df_new2['total'].values])\n",
        "vocabulary_size = len(tokenizer.word_index) + 1\n",
        "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_tokens = tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "DDt5qIljtovK"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pad5 = pad_sequences(X_train_tokens, maxlen=row_max_length, padding='post')\n",
        "X_test_pad5 = pad_sequences(X_test_tokens, maxlen=row_max_length, padding='post')"
      ],
      "metadata": {
        "id": "dvErev8ltorE"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 256\n",
        "\n",
        "learning_rate = 0.01\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, EMBEDDING_DIM, input_length=row_max_length))\n",
        "model.add(Bidirectional(GRU(units=128, return_sequences=True)))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 1, activation='linear'))\n",
        "model.compile(optimizer=optimizer, loss='mean_absolute_error', metrics=['mae'])\n",
        "\n",
        "\n",
        "epochs=15\n",
        "batch_size=64"
      ],
      "metadata": {
        "id": "DivE0oattom5"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/gpu:0'):\n",
        "  model.fit(X_train_pad5, y_train, epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCIbzQZftoik",
        "outputId": "65997479-e69b-44bc-f367-df8d5e22fead"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "180/180 [==============================] - 42s 205ms/step - loss: 47724.7930 - mae: 47724.7930\n",
            "Epoch 2/15\n",
            "180/180 [==============================] - 26s 147ms/step - loss: 29606.8457 - mae: 29606.8457\n",
            "Epoch 3/15\n",
            "180/180 [==============================] - 26s 144ms/step - loss: 24901.1602 - mae: 24901.1602\n",
            "Epoch 4/15\n",
            "180/180 [==============================] - 23s 126ms/step - loss: 21298.4805 - mae: 21298.4805\n",
            "Epoch 5/15\n",
            "180/180 [==============================] - 22s 121ms/step - loss: 19280.3984 - mae: 19280.3984\n",
            "Epoch 6/15\n",
            "180/180 [==============================] - 21s 115ms/step - loss: 18268.6855 - mae: 18268.6855\n",
            "Epoch 7/15\n",
            "180/180 [==============================] - 21s 115ms/step - loss: 16435.6641 - mae: 16435.6641\n",
            "Epoch 8/15\n",
            "180/180 [==============================] - 19s 104ms/step - loss: 14789.7275 - mae: 14789.7275\n",
            "Epoch 9/15\n",
            "180/180 [==============================] - 19s 105ms/step - loss: 13657.8877 - mae: 13657.8877\n",
            "Epoch 10/15\n",
            "180/180 [==============================] - 19s 103ms/step - loss: 13011.4951 - mae: 13011.4951\n",
            "Epoch 11/15\n",
            "180/180 [==============================] - 19s 107ms/step - loss: 12499.3643 - mae: 12499.3643\n",
            "Epoch 12/15\n",
            "180/180 [==============================] - 18s 102ms/step - loss: 12262.8320 - mae: 12262.8320\n",
            "Epoch 13/15\n",
            "180/180 [==============================] - 19s 103ms/step - loss: 11346.8896 - mae: 11346.8896\n",
            "Epoch 14/15\n",
            "180/180 [==============================] - 18s 102ms/step - loss: 10892.5557 - mae: 10892.5557\n",
            "Epoch 15/15\n",
            "180/180 [==============================] - 19s 105ms/step - loss: 10818.3066 - mae: 10818.3066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test_pad5, y_test)\n",
        "print('Test MAE:', scores[0])\n",
        "y_pred = model.predict(X_test_pad5).astype(int)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('R2 score:', round(r2 * 100, 2))"
      ],
      "metadata": {
        "id": "KzzkAMA3toeZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4fa290c-599a-4e4c-8462-0d35de69b627"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 4s 27ms/step - loss: 25705.9121 - mae: 25705.9121\n",
            "Test MAE: 25705.912109375\n",
            "90/90 [==============================] - 3s 24ms/step\n",
            "R2 score: 64.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 256\n",
        "\n",
        "learning_rate = 0.0101\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, EMBEDDING_DIM, input_length=row_max_length))\n",
        "model.add(Bidirectional(GRU(units=128, return_sequences=True)))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 1, activation='linear'))\n",
        "model.compile(optimizer=optimizer, loss='mean_absolute_error', metrics=['mae'])\n",
        "\n",
        "\n",
        "epochs=20\n",
        "batch_size=64"
      ],
      "metadata": {
        "id": "JJrqDHVvtoaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/gpu:0'):\n",
        "  model.fit(X_train_pad5, y_train, epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVM4Kp16oGkR",
        "outputId": "30e86e1a-6604-4bb8-c756-a6ccd249ec50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "180/180 [==============================] - 35s 169ms/step - loss: 49301.7891 - mae: 49301.7891\n",
            "Epoch 2/20\n",
            "180/180 [==============================] - 28s 153ms/step - loss: 31638.9082 - mae: 31638.9082\n",
            "Epoch 3/20\n",
            "180/180 [==============================] - 26s 145ms/step - loss: 24556.5977 - mae: 24556.5977\n",
            "Epoch 4/20\n",
            "180/180 [==============================] - 22s 123ms/step - loss: 21476.2520 - mae: 21476.2520\n",
            "Epoch 5/20\n",
            "180/180 [==============================] - 23s 125ms/step - loss: 19701.7207 - mae: 19701.7207\n",
            "Epoch 6/20\n",
            "180/180 [==============================] - 22s 124ms/step - loss: 17887.7520 - mae: 17887.7520\n",
            "Epoch 7/20\n",
            "180/180 [==============================] - 20s 112ms/step - loss: 16485.5605 - mae: 16485.5605\n",
            "Epoch 8/20\n",
            "180/180 [==============================] - 19s 108ms/step - loss: 15728.4492 - mae: 15728.4492\n",
            "Epoch 9/20\n",
            "180/180 [==============================] - 20s 112ms/step - loss: 14840.9971 - mae: 14840.9971\n",
            "Epoch 10/20\n",
            "180/180 [==============================] - 21s 115ms/step - loss: 14297.7480 - mae: 14297.7480\n",
            "Epoch 11/20\n",
            "180/180 [==============================] - 19s 104ms/step - loss: 13557.6631 - mae: 13557.6631\n",
            "Epoch 12/20\n",
            "180/180 [==============================] - 19s 103ms/step - loss: 12953.6572 - mae: 12953.6572\n",
            "Epoch 13/20\n",
            "180/180 [==============================] - 19s 108ms/step - loss: 12378.9219 - mae: 12378.9219\n",
            "Epoch 14/20\n",
            "180/180 [==============================] - 19s 103ms/step - loss: 12083.5762 - mae: 12083.5762\n",
            "Epoch 15/20\n",
            "180/180 [==============================] - 19s 103ms/step - loss: 11987.5498 - mae: 11987.5498\n",
            "Epoch 16/20\n",
            "180/180 [==============================] - 20s 109ms/step - loss: 11915.6055 - mae: 11915.6055\n",
            "Epoch 17/20\n",
            "180/180 [==============================] - 19s 108ms/step - loss: 11452.9092 - mae: 11452.9092\n",
            "Epoch 18/20\n",
            "180/180 [==============================] - 18s 102ms/step - loss: 10988.1631 - mae: 10988.1631\n",
            "Epoch 19/20\n",
            "180/180 [==============================] - 19s 104ms/step - loss: 10504.0977 - mae: 10504.0977\n",
            "Epoch 20/20\n",
            "180/180 [==============================] - 18s 100ms/step - loss: 10537.5352 - mae: 10537.5352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test_pad5, y_test)\n",
        "print('Test MAE:', scores[0])\n",
        "y_pred = model.predict(X_test_pad5).astype(int)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('R2 score:', round(r2, 3))"
      ],
      "metadata": {
        "id": "Nz_gQ0bbtoT3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82b97895-2d16-4c6a-c87f-484899c20f0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 3s 28ms/step - loss: 25967.3145 - mae: 25967.3145\n",
            "Test MAE: 25967.314453125\n",
            "90/90 [==============================] - 3s 24ms/step\n",
            "R2 score: 0.656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s5A0SQ0gudGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_new2['lemmatized_text'].values, df_new2.mean_salary_all.values.astype(int), test_size=0.2, random_state=10)"
      ],
      "metadata": {
        "id": "gT-pPiKNeZXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "num_rows = df_new2['lemmatized_text'].shape[0]\n",
        "tokenizer.fit_on_texts(df_new2['lemmatized_text'].values)\n",
        "row_max_length = max([len(x.split()) for x in df_new2['lemmatized_text'].values])\n",
        "vocabulary_size = len(tokenizer.word_index) + 1\n",
        "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_tokens = tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "fEYC5mmpegxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pad4 = pad_sequences(X_train_tokens, maxlen=row_max_length, padding='post')\n",
        "X_test_pad4 = pad_sequences(X_test_tokens, maxlen=row_max_length, padding='post')"
      ],
      "metadata": {
        "id": "6S5egCf7elW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 256\n",
        "\n",
        "learning_rate = 0.01\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, EMBEDDING_DIM, input_length=row_max_length))\n",
        "model.add(Bidirectional(GRU(units=128, return_sequences=True)))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 1, activation='linear'))\n",
        "model.compile(optimizer=optimizer, loss='mean_absolute_error', metrics=['mae'])\n",
        "\n",
        "\n",
        "epochs=15\n",
        "batch_size=64"
      ],
      "metadata": {
        "id": "xX4L_q2dfhFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/gpu:0'):\n",
        "  model.fit(X_train_pad4, y_train, epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBGTvImBfk7z",
        "outputId": "fd0551d8-5a22-44be-db50-2f67f5e1a354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "180/180 [==============================] - 39s 186ms/step - loss: 49603.5391 - mae: 49603.5391\n",
            "Epoch 2/15\n",
            "180/180 [==============================] - 29s 161ms/step - loss: 33941.1836 - mae: 33941.1836\n",
            "Epoch 3/15\n",
            "180/180 [==============================] - 30s 169ms/step - loss: 25378.2383 - mae: 25378.2383\n",
            "Epoch 4/15\n",
            "180/180 [==============================] - 23s 129ms/step - loss: 21924.9746 - mae: 21924.9746\n",
            "Epoch 5/15\n",
            "180/180 [==============================] - 23s 128ms/step - loss: 19553.7344 - mae: 19553.7344\n",
            "Epoch 6/15\n",
            "180/180 [==============================] - 21s 118ms/step - loss: 17622.8359 - mae: 17622.8359\n",
            "Epoch 7/15\n",
            "180/180 [==============================] - 21s 117ms/step - loss: 15982.1455 - mae: 15982.1455\n",
            "Epoch 8/15\n",
            "180/180 [==============================] - 20s 114ms/step - loss: 15181.3984 - mae: 15181.3984\n",
            "Epoch 9/15\n",
            "180/180 [==============================] - 20s 109ms/step - loss: 14670.9004 - mae: 14670.9004\n",
            "Epoch 10/15\n",
            "180/180 [==============================] - 19s 107ms/step - loss: 13877.4785 - mae: 13877.4785\n",
            "Epoch 11/15\n",
            "180/180 [==============================] - 20s 111ms/step - loss: 12803.6426 - mae: 12803.6426\n",
            "Epoch 12/15\n",
            "180/180 [==============================] - 19s 107ms/step - loss: 12477.8447 - mae: 12477.8447\n",
            "Epoch 13/15\n",
            "180/180 [==============================] - 19s 108ms/step - loss: 11876.4912 - mae: 11876.4912\n",
            "Epoch 14/15\n",
            "180/180 [==============================] - 19s 103ms/step - loss: 11305.3350 - mae: 11305.3350\n",
            "Epoch 15/15\n",
            "180/180 [==============================] - 19s 104ms/step - loss: 11018.3818 - mae: 11018.3818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test_pad4, y_test)\n",
        "print('Test MAE:', scores[0])\n",
        "y_pred = model.predict(X_test_pad4).astype(int)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('R2 score:', round(r2 * 100, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Exfjgsnfq7L",
        "outputId": "cd83ae60-7a06-4a4c-8da2-b549f7193778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 3s 27ms/step - loss: 25851.3457 - mae: 25851.3457\n",
            "Test MAE: 25851.345703125\n",
            "90/90 [==============================] - 3s 28ms/step\n",
            "R2 score: 65.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 256\n",
        "\n",
        "learning_rate = 0.01\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "model1=Sequential()\n",
        "model1.add(Embedding(vocabulary_size, EMBEDDING_DIM, input_length=row_max_length))\n",
        "model1.add(Bidirectional(GRU(units=128, return_sequences=True)))\n",
        "model1.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "model1.add(MaxPooling1D(pool_size=2))\n",
        "model1.add(Flatten())\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(Dense(units = 1, activation='relu'))\n",
        "model1.compile(optimizer=optimizer, loss='mean_absolute_error', metrics=['mae'])\n",
        "\n",
        "\n",
        "epochs=12\n",
        "batch_size=128"
      ],
      "metadata": {
        "id": "cZDkCBhfgjsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/gpu:0'):\n",
        "  model1.fit(X_train_pad4, y_train, epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpOz5S9vhkkh",
        "outputId": "e570ec67-c162-401c-a1b1-50e38f1be263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "90/90 [==============================] - 24s 224ms/step - loss: 51752.2500 - mae: 51752.2500\n",
            "Epoch 2/12\n",
            "90/90 [==============================] - 19s 208ms/step - loss: 44561.9375 - mae: 44561.9375\n",
            "Epoch 3/12\n",
            "90/90 [==============================] - 19s 213ms/step - loss: 39753.5781 - mae: 39753.5781\n",
            "Epoch 4/12\n",
            "90/90 [==============================] - 18s 197ms/step - loss: 31099.4102 - mae: 31099.4102\n",
            "Epoch 5/12\n",
            "90/90 [==============================] - 17s 194ms/step - loss: 25540.5586 - mae: 25540.5586\n",
            "Epoch 6/12\n",
            "90/90 [==============================] - 17s 190ms/step - loss: 21755.2500 - mae: 21755.2500\n",
            "Epoch 7/12\n",
            "90/90 [==============================] - 17s 187ms/step - loss: 19667.3438 - mae: 19667.3438\n",
            "Epoch 8/12\n",
            "90/90 [==============================] - 16s 179ms/step - loss: 18282.4355 - mae: 18282.4355\n",
            "Epoch 9/12\n",
            "90/90 [==============================] - 18s 201ms/step - loss: 16655.7246 - mae: 16655.7246\n",
            "Epoch 10/12\n",
            "90/90 [==============================] - 16s 178ms/step - loss: 16095.5635 - mae: 16095.5635\n",
            "Epoch 11/12\n",
            "90/90 [==============================] - 15s 172ms/step - loss: 15304.8242 - mae: 15304.8242\n",
            "Epoch 12/12\n",
            "90/90 [==============================] - 16s 178ms/step - loss: 14532.5020 - mae: 14532.5020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model1.evaluate(X_test_pad4, y_test)\n",
        "print('Test MAE:', scores[0])\n",
        "y_pred = model1.predict(X_test_pad4).astype(int)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('R2 score:', round(r2 * 100, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6birr-Qhgo8",
        "outputId": "2c443475-1e32-420b-ac5c-5832dec4cfd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 4s 32ms/step - loss: 27076.8516 - mae: 27076.8516\n",
            "Test MAE: 27076.8515625\n",
            "90/90 [==============================] - 3s 26ms/step\n",
            "R2 score: 63.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 256\n",
        "\n",
        "learning_rate = 0.01\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, EMBEDDING_DIM, input_length=row_max_length))\n",
        "model.add(Bidirectional(GRU(units=128, return_sequences=True)))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 1, activation='linear'))\n",
        "model.compile(optimizer=optimizer, loss='mean_absolute_error', metrics=['mae'])\n",
        "\n",
        "\n",
        "epochs=15\n",
        "batch_size=64"
      ],
      "metadata": {
        "id": "L5tCJyYnnuED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/gpu:0'):\n",
        "  model.fit(X_train_pad3, y_train, epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETsnwFydkAVV",
        "outputId": "67c3c44f-24fa-4e47-cfd0-6dce3468d82c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "180/180 [==============================] - 33s 146ms/step - loss: 46885.0156 - mae: 46885.0156\n",
            "Epoch 2/15\n",
            "180/180 [==============================] - 20s 109ms/step - loss: 31657.2246 - mae: 31657.2246\n",
            "Epoch 3/15\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 27727.1094 - mae: 27727.1094\n",
            "Epoch 4/15\n",
            "180/180 [==============================] - 18s 97ms/step - loss: 25924.4453 - mae: 25924.4453\n",
            "Epoch 5/15\n",
            "180/180 [==============================] - 18s 102ms/step - loss: 24750.2480 - mae: 24750.2480\n",
            "Epoch 6/15\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 24096.6895 - mae: 24096.6895\n",
            "Epoch 7/15\n",
            "180/180 [==============================] - 17s 96ms/step - loss: 23149.0586 - mae: 23149.0586\n",
            "Epoch 8/15\n",
            "180/180 [==============================] - 17s 96ms/step - loss: 22426.1328 - mae: 22426.1328\n",
            "Epoch 9/15\n",
            "180/180 [==============================] - 17s 96ms/step - loss: 22161.7188 - mae: 22161.7188\n",
            "Epoch 10/15\n",
            "180/180 [==============================] - 17s 96ms/step - loss: 21717.2871 - mae: 21717.2871\n",
            "Epoch 11/15\n",
            "180/180 [==============================] - 17s 97ms/step - loss: 21674.5195 - mae: 21674.5195\n",
            "Epoch 12/15\n",
            "180/180 [==============================] - 17s 95ms/step - loss: 21196.5312 - mae: 21196.5312\n",
            "Epoch 13/15\n",
            "180/180 [==============================] - 18s 98ms/step - loss: 21118.4043 - mae: 21118.4043\n",
            "Epoch 14/15\n",
            "180/180 [==============================] - 17s 96ms/step - loss: 21032.3203 - mae: 21032.3203\n",
            "Epoch 15/15\n",
            "180/180 [==============================] - 17s 96ms/step - loss: 20578.7715 - mae: 20578.7715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test_pad3, y_test)\n",
        "print('Test MAE:', scores[0])\n",
        "y_pred = model.predict(X_test_pad3).astype(int)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('R2 score:', round(r2, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLUx7I3mkAtJ",
        "outputId": "04c900af-2d6a-4368-f018-278a73b86b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 3s 26ms/step - loss: 27104.0195 - mae: 27104.0195\n",
            "Test MAE: 27104.01953125\n",
            "90/90 [==============================] - 3s 27ms/step\n",
            "R2 score: 0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m6Ejhf1xlF2r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}